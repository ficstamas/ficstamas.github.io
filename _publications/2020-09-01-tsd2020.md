---
title: "Interpreting Word Embeddings Using a Distribution Agnostic Approach Employing Hellinger Distance"
collection: publications
permalink: /publication/tsd2020
excerpt: 'Word embeddings can encode semantic and syntactic features and have achieved many recent successes in solving NLP tasks. Despite their successes, it is not trivial to directly extract lexical information out of them. In this paper, we propose a transformation of the embedding space to a more interpretable one using the Hellinger distance. We additionally suggest a distribution-agnostic approach using Kernel Density Estimation. A method is introduced to measure the interpretability of the word embeddings. Our results suggest that Hellinger based calculation gives a  1.35% improvement on average over the Bhattacharyya distance in terms of interpretability and adapts better to unknown words.'
date: 2020-09-01
venue: 'Text, Speech, and Dialogue. TSD 2020'
paperurl: 'https://link.springer.com/chapter/10.1007%2F978-3-030-58323-1_21'
citation: 'Ficsor T., Berend G. (2020) Interpreting Word Embeddings Using a Distribution Agnostic Approach Employing Hellinger Distance. In: Sojka P., Kopeček I., Pala K., Horák A. (eds) Text, Speech, and Dialogue. TSD 2020. Lecture Notes in Computer Science, vol 12284. Springer, Cham. https://doi.org/10.1007/978-3-030-58323-1_21'
---


Code is Available on [Github](https://github.com/ficstamas/word_embedding_interpretability)

Cite As:

```
@InProceedings{10.1007/978-3-030-58323-1_21,
    author="Ficsor, Tam{\'a}s and Berend, G{\'a}bor",
    editor="Sojka, Petr and Kope{\v{c}}ek, Ivan and Pala, Karel and Hor{\'a}k, Ale{\v{s}}",
    title="Interpreting Word Embeddings Using a Distribution Agnostic Approach Employing Hellinger Distance",
    booktitle="Text, Speech, and Dialogue",
    year="2020",
    publisher="Springer International Publishing",
    address="Cham",
    pages="197--205",
    abstract="Word embeddings can encode semantic and syntactic features and have achieved many recent successes in solving NLP tasks. Despite their successes, it is not trivial to directly extract lexical information out of them. In this paper, we propose a transformation of the embedding space to a more interpretable one using the Hellinger distance. We additionally suggest a distribution-agnostic approach using Kernel Density Estimation. A method is introduced to measure the interpretability of the word embeddings. Our results suggest that Hellinger based calculation gives a  1.35{\%} improvement on average over the Bhattacharyya distance in terms of interpretability and adapts better to unknown words.",
    isbn="978-3-030-58323-1"
}
```